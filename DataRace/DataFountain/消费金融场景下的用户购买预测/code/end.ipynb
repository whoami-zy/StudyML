{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_agg = pd.read_csv('./train/train_agg.csv',header=0,sep='\\t')\n",
    "train_log = pd.read_csv('./train/train_log_re_4.csv',header=0,sep='\\t')\n",
    "log_agg = pd.merge(train_agg,train_log,on='USRID',how='left')\n",
    "train_flg = pd.read_csv('./train/train_flg.csv',header=0,sep='\\t')\n",
    "train_agg_flag = pd.merge(train_flg,log_agg,on='USRID')\n",
    "train_agg_flag.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg_flag['V4*V7'] = train_agg_flag.V4 * train_agg_flag.V7\n",
    "train_agg_flag['V4*V17'] = train_agg_flag.V4 * train_agg_flag.V17\n",
    "train_agg_flag['V5*V7'] = train_agg_flag.V5 * train_agg_flag.V7\n",
    "train_agg_flag['V5*V17'] = train_agg_flag.V5 * train_agg_flag.V17\n",
    "train_agg_flag['V5*V30'] = train_agg_flag.V5 * train_agg_flag.V30\n",
    "train_agg_flag['V7*CC'] = train_agg_flag.V7 * train_agg_flag.CC\n",
    "train_agg_flag['V1+V7'] = train_agg_flag.V7 + train_agg_flag.V1\n",
    "train_agg_flag['V6+CC'] = train_agg_flag.V6 + train_agg_flag.CC\n",
    "train_agg_flag['V6-CC'] = train_agg_flag.V6 - train_agg_flag.CC\n",
    "train_agg_flag['V7-V28'] = train_agg_flag.V7 - train_agg_flag.V28\n",
    "# train_agg_flag['V7/CC'] = train_agg_flag.V7 / train_agg_flag.CC\n",
    "train_agg_flag['V7+CC'] = train_agg_flag.V7 + train_agg_flag.CC\n",
    "train_agg_flag['V28-V29'] = train_agg_flag.V28 - train_agg_flag.V29\n",
    "# train_agg_flag['V28/V29'] = train_agg_flag.V28 / train_agg_flag.V29\n",
    "# train_agg_flag['V6/CC'] = train_agg_flag.V6 / train_agg_flag.CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_colliner_features(x,threshold):\n",
    "    y = x['FLAG']\n",
    "    x = x.drop('FLAG',1)\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) -1)\n",
    "    drop_cols = []\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1),(i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            if val > threshold:\n",
    "                drop_cols.append(col.values[0])\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(drops,1)\n",
    "    x['FLAG'] = y\n",
    "    return x\n",
    "train_agg_flag = remove_colliner_features(train_agg_flag,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsT = train_agg_flag.drop('FLAG',1).drop('USRID',1).drop('web',1).columns\n",
    "features_x = train_agg_flag.drop('FLAG',1).drop('USRID',1).drop('web',1).get_values()\n",
    "features_y = train_agg_flag.FLAG.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columnsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_agg = pd.read_csv('./test/test_agg.csv',header=0,sep='\\t')\n",
    "test_log = pd.read_csv('./test/test_log_re_4.csv',header=0,sep='\\t')\n",
    "test_log_agg = pd.merge(test_agg,test_log,on='USRID',how='left')\n",
    "test_log_agg.fillna(0,inplace=True)\n",
    "test_log_agg['V4*V7'] = test_log_agg.V4 * test_log_agg.V7\n",
    "test_log_agg['V4*V17'] = test_log_agg.V4 * test_log_agg.V17\n",
    "test_log_agg['V5*V7'] = test_log_agg.V5 * test_log_agg.V7\n",
    "test_log_agg['V5*V17'] = test_log_agg.V5 * test_log_agg.V17\n",
    "test_log_agg['V5*V30'] = test_log_agg.V5 * test_log_agg.V30\n",
    "test_log_agg['V7*CC'] = test_log_agg.V7 * test_log_agg.CC\n",
    "test_log_agg['V1+V7'] = test_log_agg.V7 + test_log_agg.V1\n",
    "test_log_agg['V6+CC'] = test_log_agg.V6 + test_log_agg.CC\n",
    "test_log_agg['V6-CC'] = test_log_agg.V6 - test_log_agg.CC\n",
    "test_log_agg['V7-V28'] = test_log_agg.V7 - test_log_agg.V28\n",
    "test_log_agg['V7/CC'] = test_log_agg.V7 / test_log_agg.CC\n",
    "test_log_agg['V7+CC'] = test_log_agg.V7 + test_log_agg.CC\n",
    "test_log_agg['V28-V29'] = test_log_agg.V28 - test_log_agg.V29\n",
    "test_log_agg['V28/V29'] = test_log_agg.V28 / test_log_agg.V29\n",
    "test_log_agg['V6/CC'] = test_log_agg.V6 / test_log_agg.CC\n",
    "key = test_log_agg.USRID\n",
    "# test = test_features.get_values()\n",
    "test = test_log_agg[columnsT].get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.850152\n",
      "[500]\tvalid_0's auc: 0.852906\n",
      "Early stopping, best iteration is:\n",
      "[599]\tvalid_0's auc: 0.853207\n",
      "Start predicting...\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.84475\n",
      "[500]\tvalid_0's auc: 0.848905\n",
      "[750]\tvalid_0's auc: 0.850709\n",
      "[1000]\tvalid_0's auc: 0.85107\n",
      "Early stopping, best iteration is:\n",
      "[1005]\tvalid_0's auc: 0.851106\n",
      "Start predicting...\n",
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.852796\n",
      "[500]\tvalid_0's auc: 0.858028\n",
      "[750]\tvalid_0's auc: 0.860059\n",
      "Early stopping, best iteration is:\n",
      "[904]\tvalid_0's auc: 0.860529\n",
      "Start predicting...\n",
      "xx_cv 0.8549474997594632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "xx_cv = []\n",
    "xx_pre = []\n",
    "N = 3\n",
    "skf = StratifiedKFold(n_splits=N,shuffle=False,random_state=42)\n",
    "for train_in,test_in in skf.split(features_x,features_y):\n",
    "    X_train,X_test,y_train,y_test = features_x[train_in],features_x[test_in],features_y[train_in],features_y[test_in]\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'auc'},\n",
    "        'num_leaves': 15,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "         'max_depth':4,\n",
    "         'lambda_l1':1.5,\n",
    "        'lambda_l2':0.0,\n",
    "        'max_bin':100,\n",
    "        'scale_pos_weight':20,\n",
    "    }\n",
    "    params['min_data_in_leaf'] = 200\n",
    "    print('Start training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    verbose_eval=250,\n",
    "                    early_stopping_rounds=50)\n",
    "\n",
    "    # print('Save model...')\n",
    "    # save model to file\n",
    "    # gbm.save_model('model.txt')\n",
    "\n",
    "    print('Start predicting...')\n",
    "    y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "    xx_cv.append(roc_auc_score(y_test,y_pred))\n",
    "    xx_pre.append(gbm.predict(test, num_iteration=gbm.best_iteration))\n",
    "\n",
    "s = 0\n",
    "for i in xx_pre:\n",
    "    s = s + i\n",
    "\n",
    "s = s /N\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['USRID'] = list(key)\n",
    "res['RST'] = list(s)\n",
    "\n",
    "print('xx_cv',np.mean(xx_cv))\n",
    "\n",
    "import time\n",
    "time_date = time.strftime('%Y-%m-%d',time.localtime(time.time()))\n",
    "res.to_csv('./submit/%s_%s.csv'%(str(time_date),str(np.mean(xx_cv)).split('.')[1]),index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "Start predicting...\n",
      "Start predicting...\n",
      "Start predicting...\n",
      "Start predicting...\n",
      "xx_cv 0.8481004963347125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "N = 5\n",
    "skf = StratifiedKFold(n_splits=N,shuffle=False,random_state=42)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "xx_cv = []\n",
    "xx_pre = []\n",
    "for train_in,test_in in skf.split(features_x,features_y):\n",
    "    X_train,X_test,y_train,y_test = features_x[train_in],features_x[test_in],features_y[train_in],features_y[test_in]\n",
    "\n",
    "    rf0 = RandomForestClassifier(min_samples_split=100,min_samples_leaf=50,max_depth=10,bootstrap=False,max_features='sqrt' ,random_state=10,min_weight_fraction_leaf=0,n_estimators=4000)\n",
    "    rf0.fit(X_train,y_train)\n",
    "    y_predprob = rf0.predict_proba(X_test)[:,1]\n",
    "    print('Start predicting...')\n",
    "    xx_cv.append(roc_auc_score(y_test,y_predprob))\n",
    "    xx_pre.append(rf0.predict_proba(test)[:, 1])\n",
    "\n",
    "s = 0\n",
    "for i in xx_pre:\n",
    "    s = s + i\n",
    "\n",
    "s = s /N\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['USRID'] = list(key)\n",
    "res['RST'] = list(s)\n",
    "\n",
    "print('xx_cv',np.mean(xx_cv))\n",
    "\n",
    "import time\n",
    "time_date = time.strftime('%Y-%m-%d',time.localtime(time.time()))\n",
    "res.to_csv('./submit/%s_%s.csv'%(str(time_date),str(np.mean(xx_cv)).split('.')[1]),index=False,sep='\\t')                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84811, std: 0.00386, params: {}], {}, 0.8481078553184083)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_test1= {}\n",
    "gsearch1= GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                 min_samples_leaf=50,max_depth=10,bootstrap=False,max_features='sqrt' ,random_state=10,min_weight_fraction_leaf=0,n_estimators=4000),\n",
    "                       param_grid =param_test1, scoring='roc_auc',cv=3)\n",
    "gsearch1.fit(features_x,features_y)\n",
    "gsearch1.grid_scores_,gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.feature_importance()\n",
    "train_agg_flag.drop('FLAG',1).drop('USRID',1).columns\n",
    "def getIm(score,col):\n",
    "    if len(score) != len(col):\n",
    "        print('err')\n",
    "    for i in range(len(score)):\n",
    "        if score[i]>250:\n",
    "            pass\n",
    "        print('score:{0}, col:{1}'.format(score[i],col[i]))\n",
    "getIm(cat_model.feature_importances_,train_agg_flag.drop('FLAG',1).drop('USRID',1).drop('web',1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
