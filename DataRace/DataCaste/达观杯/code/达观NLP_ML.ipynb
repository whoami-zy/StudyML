{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"word_seg\"\n",
    "train = pd.read_csv('../data/train_set.csv')\n",
    "test = pd.read_csv('../data/test_set.csv')\n",
    "test_id = test[\"id\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_doc = TfidfVectorizer(ngram_range=(1,2),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=400000,analyzer='word')\n",
    "trn_term_doc = vec_doc.fit_transform(train[column])\n",
    "test_term_doc = vec_doc.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_term_doc.npz', trn_term_doc)\n",
    "# sparse.save_npz('./test_term_doc.npz', test_term_doc)\n",
    "\n",
    "trn_term_doc = sparse.load_npz('./trn_term_doc.npz')\n",
    "test_term_doc = sparse.load_npz('./test_term_doc.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_word = TfidfVectorizer(ngram_range=(1,1),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=400000,analyzer='word')\n",
    "trn_term_word = vec_word.fit_transform(train[column])\n",
    "test_term_word = vec_word.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_term_word.npz', trn_term_word)\n",
    "# sparse.save_npz('./test_term_word.npz', test_term_word)\n",
    "\n",
    "trn_term_word = sparse.load_npz('./trn_term_word.npz')\n",
    "test_term_word = sparse.load_npz('./test_term_word.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_word_nramThree = TfidfVectorizer(ngram_range=(3,3),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=400000,analyzer='word')\n",
    "trn_term_word_three = vec_word_nramThree.fit_transform(train[column])\n",
    "test_term_word_three = vec_word_nramThree.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_term_word_three.npz', trn_term_word_three)\n",
    "# sparse.save_npz('./test_term_word_three.npz', test_term_word_three)\n",
    "\n",
    "trn_term_word_three = sparse.load_npz('./trn_term_word_three.npz')\n",
    "test_term_word_three = sparse.load_npz('./test_term_word_three.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_word_nramfour = TfidfVectorizer(ngram_range=(4,4),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=400000,analyzer='word')\n",
    "trn_term_word_four = vec_word_nramfour.fit_transform(train[column])\n",
    "test_term_word_four = vec_word_nramfour.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_term_word_four.npz', trn_term_word_four)\n",
    "# sparse.save_npz('./test_term_word_four.npz', test_term_word_four)\n",
    "\n",
    "trn_term_word_four = sparse.load_npz('./trn_term_word_four.npz')\n",
    "test_term_word_four = sparse.load_npz('./test_term_word_four.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_word_nramfive = TfidfVectorizer(ngram_range=(5,5),min_df=3, max_df=1.0,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=400000,analyzer='char')\n",
    "trn_term_word_five = vec_word_nramfive.fit_transform(train[column])\n",
    "test_term_word_five = vec_word_nramfive.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_term_word_five.npz', trn_term_word_five)\n",
    "# sparse.save_npz('./test_term_word_five.npz', test_term_word_five)\n",
    "trn_term_word_five = sparse.load_npz('./trn_term_word_five.npz')\n",
    "test_term_word_five = sparse.load_npz('./test_term_word_five.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_char = TfidfVectorizer(ngram_range=(1,2),min_df=3,use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=10000,analyzer='char')\n",
    "trn_char = vec_char.fit_transform(train[\"article\"])\n",
    "test_char = vec_char.transform(test[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('./trn_char.npz', trn_char)\n",
    "# sparse.save_npz('./test_char.npz', test_char)\n",
    "\n",
    "trn_char = sparse.load_npz('./trn_char.npz')\n",
    "test_char = sparse.load_npz('./test_char.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docLen  =pd.DataFrame( np.array(train[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "doclen_word = pd.DataFrame( np.array(train['article'].map(lambda x : len(x.split(\" \")))/train[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))\n",
    "docLen_test  =pd.DataFrame( np.array(test[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "doclen_word_test = pd.DataFrame( np.array(test['article'].map(lambda x : len(x.split(\" \")))/test[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feaure =  hstack([trn_term_doc,trn_term_word,trn_term_word_three,trn_term_word_four,trn_char,doclen_word]).tocsr()\n",
    "test_festure =  hstack([test_term_doc,test_term_word,test_term_word_three,test_term_word_four,test_char,doclen_word_test]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_festure.shape\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用计数后tfidf,效果提升不大，维度上升60w,试过chi2降维，效果降低。，10折比5折有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_select(corpus, labels, k=1000):\n",
    "#     \"\"\"\n",
    "#     select top k features through chi-square test\n",
    "#     \"\"\"\n",
    "#     bin_cv = CountVectorizer(binary=True)\n",
    "#     le = LabelEncoder()\n",
    "#     X = bin_cv.fit_transform(corpus)\n",
    "#     print(\"countVector Shap: \",X.shape)\n",
    "#     y = le.fit_transform(labels).reshape(-1, 1)\n",
    "\n",
    "#     k = min(X.shape[1], k)\n",
    "#     skb = SelectKBest(chi2, k=k)\n",
    "#     skb.fit(X, y)\n",
    "\n",
    "#     feature_ids = skb.get_support(indices=True)\n",
    "#     feature_names = bin_cv.get_feature_names()\n",
    "#     vocab = {}\n",
    "\n",
    "#     for new_fid, old_fid in enumerate(feature_ids):\n",
    "#         feature_name = feature_names[old_fid]\n",
    "#         vocab[feature_name] = new_fid\n",
    "\n",
    "#     # we only care about the final extracted feature vocabulary\n",
    "#     return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler(with_mean=False)\n",
    "ss.fit(train_feaure)\n",
    "X_train_std = ss.transform(train_feaure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = ss.transform(test_festure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb = SelectKBest(chi2, k=840000)\n",
    "train_feaure_chi = skb.fit_transform(X_train_std, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feaure_chi = skb.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = (pd.Series(train['class'])-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N = 2\n",
    "# skf = StratifiedKFold(n_splits=N,shuffle=True,random_state=42)\n",
    "# xx_cv = []\n",
    "# xx_pred = []\n",
    "# for train_in,test_in in skf.split(train_feaure,y_all):\n",
    "#     X_train,X_test,y_train,y_test =train_feaure[train_in],train_feaure[test_in],y_all[train_in],y_all[test_in]\n",
    "#     lin_svm = svm.LinearSVC(C=1.0,random_state=2018,max_iter=5000)\n",
    "#     lin_svm.fit(X_train,y_train)\n",
    "#     print('Start predicting...')\n",
    "#     preds = lin_svm.predict(X_test)\n",
    "# #     y_pred = pd.Series(y_pred).map(lambda x:x+1)\n",
    "#     fscoer = f1_score(y_test, preds, average='micro')\n",
    "#     print(fscoer)\n",
    "#     xx_cv.append(fscoer)\n",
    "# #     xx_pred.append(lin_svm.predict(test_term_doc))\n",
    "#     print(classification_report(y_test,preds))\n",
    "#     print('-------------------end---------------------------')\n",
    "# print('END:  ',np.mean(xx_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test =train_test_split(train_feaure,y_all,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0.1,0.4,0.6,0.7,0.8,0.9]:\n",
    "#     lin_svm = svm.LinearSVC(C=i,random_state=2018,max_iter=500)\n",
    "#     lin_svm.fit(X_train,y_train)\n",
    "#     print('Start predicting...     ',i)\n",
    "#     preds = lin_svm.predict(X_test)\n",
    "#     fscoer = f1_score(y_test, preds, average='micro')\n",
    "#     print(fscoer)\n",
    "#     print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872180941207144\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.56      0.60      1639\n",
      "          1       0.79      0.75      0.77       852\n",
      "          2       0.88      0.88      0.88      2439\n",
      "          3       0.86      0.83      0.85      1143\n",
      "          4       0.84      0.76      0.80       697\n",
      "          5       0.94      0.90      0.92      2114\n",
      "          6       0.72      0.64      0.68       931\n",
      "          7       0.69      0.77      0.73      2118\n",
      "          8       0.93      0.94      0.93      2347\n",
      "          9       0.71      0.70      0.70      1484\n",
      "         10       0.67      0.73      0.70      1076\n",
      "         11       0.69      0.67      0.68      1604\n",
      "         12       0.74      0.79      0.77      2406\n",
      "         13       0.77      0.81      0.79      1986\n",
      "         14       0.91      0.90      0.90      2215\n",
      "         15       0.80      0.67      0.73       936\n",
      "         16       0.76      0.73      0.74       938\n",
      "         17       0.86      0.88      0.87      2130\n",
      "         18       0.59      0.64      0.61      1629\n",
      "\n",
      "avg / total       0.79      0.79      0.79     30684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=6,dual=True)\n",
    "lr.fit(X_train,y_train)\n",
    "ypred = lr.predict_proba(X_test)\n",
    "preds=np.argmax(ypred,axis=1)\n",
    "fscoer = f1_score(y_test, preds, average='micro')\n",
    "print(fscoer)\n",
    "print(classification_report(y_test,preds))\n",
    "#0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lr.predict_proba(test_festure)\n",
    "preds=np.argmax(ypred,axis=1)\n",
    "# fscoer = f1_score(y_test, preds, average='micro')\n",
    "# print(fscoer)\n",
    "# print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['id'] = test_id\n",
    "res['class'] = pd.Series(preds).map(lambda x : x+1)\n",
    "print(res.head())\n",
    "res.to_csv('../data/baseline_lr.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# N = 2\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# skf = StratifiedKFold(n_splits=N,shuffle=False,random_state=42)\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from xgboost import XGBClassifier\n",
    "# xx_cv = []\n",
    "# xx_pred = []\n",
    "# for train_in,test_in in skf.split(trn_term_doc,y_all):\n",
    "#     X_train,X_test,y_train,y_test =trn_term_doc[train_in],trn_term_doc[test_in],y_all[train_in],y_all[test_in]\n",
    "#     xgbc = XGBClassifier(\n",
    "#         learning_rate =0.1,\n",
    "#         n_estimators=500,\n",
    "#         max_depth=6,\n",
    "#         min_child_weight=0,\n",
    "#         gamma=0,\n",
    "#         subsample=0.7,\n",
    "#         colsample_bytree=0.7,\n",
    "#         objective= 'multi:softmax',\n",
    "#         num_class=19,\n",
    "#         eval_metric='merror',\n",
    "#         nthread=-1,\n",
    "#         scale_pos_weight=1,\n",
    "#         seed=27)\n",
    "#     print('Start predicting...')\n",
    "#     xgbc_enc = OneHotEncoder()  \n",
    "#     lin_svm = svm.LinearSVC(C=1.0,random_state=2018,max_iter=5000)\n",
    "#     xgbc.fit(X_train,y_train)\n",
    "#     xgbc_enc.fit(xgbc.apply(X_train)[:, :])\n",
    "#     lin_svm.fit(xgbc_enc.transform(xgbc.apply(X_train)[:, :]), y_train)\n",
    "#     y_xgbc_lr_test = lin_svm.predict(xgbc_enc.transform(xgbc.apply(X_test)[:,:]))\n",
    "# #     preds=np.argmax(y_xgbc_lr_test,axis=1)\n",
    "#     print(y_xgbc_lr_test)\n",
    "# #     y_pred = pd.Series(y_pred).map(lambda x:x+1)\n",
    "#     fscoer = f1_score(y_test, y_xgbc_lr_test, average='micro')\n",
    "#     print(fscoer)\n",
    "#     xx_cv.append(fscoer)\n",
    "# #     xx_pred.append(lin_svm.predict(test_term_doc))\n",
    "#     print(classification_report(y_test,y_xgbc_lr_test))\n",
    "#     print('-------------------end---------------------------')\n",
    "# print('END:  ',np.mean(xx_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# N = 3\n",
    "# skf = StratifiedKFold(n_splits=N,shuffle=False,random_state=42)\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# xx_cv = []\n",
    "# xx_pred = []\n",
    "# for train_in,test_in in skf.split(xtrain_scl,y_all):\n",
    "#     X_train,X_test,y_train,y_test = xtrain_scl[train_in],xtrain_scl[test_in],y_all[train_in],y_all[test_in]\n",
    "#     clf = MultinomialNB(alpha = 0.01)\n",
    "#     clf.fit(X_train, y_train);\n",
    "#     print('Start predicting...')\n",
    "#     preds = clf.predict(X_test)\n",
    "# #     y_pred = pd.Series(y_pred).map(lambda x:x+1)\n",
    "#     fscoer = f1_score(y_test, preds, average='micro')\n",
    "#     print(fscoer)\n",
    "#     xx_cv.append(fscoer)\n",
    "# #     xx_pred.append(lin_svm.predict(test_term_doc))\n",
    "#     print(classification_report(y_test,preds))\n",
    "#     print('-------------------end---------------------------')\n",
    "# print('END:  ',np.mean(xx_cv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
